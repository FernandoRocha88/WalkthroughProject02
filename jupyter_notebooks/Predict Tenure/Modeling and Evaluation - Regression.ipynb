{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Modeling and Evaluation - Regression.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Fit and evaluate a regression model to predict tenure levels for a prospect that will likely churn\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
        "* instructions on which variables to use for data cleaning and feature engineering. They are found on its respectives notebooks.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* ML pipeline to predict tenure, X_train columns, best pipeline features, labels map\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbuGQj9lDAEo"
      },
      "source": [
        "# Install and Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAx1yVscyB3M"
      },
      "source": [
        "* You eventually will need to restart runtime when installing packages, please note cell output when installing a package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBfLDnhx-2k"
      },
      "source": [
        "! pip install feature-engine==1.0.2\n",
        "! pip install scikit-learn==0.24.2\n",
        "# ! pip install pandas-profiling==2.11.0\n",
        "# ! pip install ppscore==1.2.0\n",
        "# ! pip install pingouin==0.3.12\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUFuYskeybZL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit â†’ Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgHiVgPviuMx"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtPQ7EnPiuMy"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhDHrzxEiuMz"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8aYwLkiuMz"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JjRkDt1eOAr"
      },
      "source": [
        "* **Credentials format disclaimer**: when opening Jupyter notebooks in Colab that are hosted at GitHub, we ask you to not consider special characters in your **password**, like @ ! \" # $ % & ' ( ) * + , - . / :;< = > ? @ [\\ ]^_ ` { } | ~\n",
        "  * Otherwise it will not work properly the git push command, since the credentials are concatenated in the command: username:password@github.com/username/repo , the git push command will not work properly when these terms have special characters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_amd2ygiuM0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I2eQe-YiuM0"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfD0o1u1iuM0"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGOPTqcmiuM1"
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uhzcFjeiuM1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS3yEKFJiuM1"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_tFmsYgiuM2"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CveMisgfiuM2"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the session, pushes it to the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "import uuid\n",
        "file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "print(\"\\n\\n\")\n",
        "os.remove(f\"{file_name}.txt\")\n",
        "! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpFreVRiuM3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "257gMsNhiuM3"
      },
      "source": [
        "### **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUla5863TKyk"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzjZgWV-TMOB"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_xeleqiuM4"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpFefbLXiuM4"
      },
      "source": [
        "CommitMsg = \"update\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msFKrJ6fiuM5"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxYGf_yiuM5"
      },
      "source": [
        "!git push origin main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXKlJFX0iuM5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7CNgZ_TiuM6"
      },
      "source": [
        "### **Delete** Cloned Repo from current Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cobdGQGZfZG7"
      },
      "source": [
        "* Delete cloned repo and move current directory to /content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UACixuaiuM6"
      },
      "source": [
        "%cd /content\n",
        "import os\n",
        "!rm -rf {os.environ['RepoName']}\n",
        "\n",
        "print(f\"\\n * Please refresh session folder to validate that {os.environ['RepoName']} folder was removed from this session.\")\n",
        "print(f\"\\n\\n* Current session directory is:  {os.getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MKNQXhQiuM7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7DU_ekbtX8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/TelcoCustomerChurn.csv\")\n",
        "      .query(\"Churn == 1\")  # subset churned customer\n",
        "      .drop(labels=['customerID','TotalCharges','Churn'],axis=1)  \n",
        "                    # variables we will not need for this project\n",
        "                    # we will not need Churn, since it is has only 1\n",
        "      # .filter(['MultipleLines', 'Partner', 'Contract', 'PaymentMethod', \n",
        "      #          'DeviceProtection', 'OnlineSecurity', 'MonthlyCharges', 'StreamingTV',\n",
        "      #          'tenure'])\n",
        "  )\n",
        "\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt-X8SWKYLbn"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krjAk78Tbyhv"
      },
      "source": [
        "# ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZWZHhpYaDjf"
      },
      "source": [
        "## ML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr9LUaOV08Su"
      },
      "source": [
        "* In the ML Pipeline, we are using the raw data, therefore we need to create the pipeline with data cleaninig and feature engineering steps\n",
        "  * This pipeline will be used in the Train Set, Test Set and Live Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzSg8Iwjl7dz"
      },
      "source": [
        "### Imports needed at Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFUD8ofWl7nm"
      },
      "source": [
        "from config import config\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.selection import DropFeatures ##################\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "\n",
        "\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge,RidgeCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import LassoLars\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr0kimOaAjL6"
      },
      "source": [
        "### Pipeline for Data Cleaning and Feat Eng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6keis6ao8LA"
      },
      "source": [
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "  pipeline_base = Pipeline(\n",
        "      [\n",
        "\n",
        "      (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                  variables = [ 'gender', 'Partner', 'Dependents', 'PhoneService',\n",
        "                                                               'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                                                               'OnlineBackup','DeviceProtection', 'TechSupport', \n",
        "                                                               'StreamingTV', 'StreamingMovies','Contract', \n",
        "                                                               'PaperlessBilling', 'PaymentMethod']\n",
        "                                                  )\n",
        "      ),\n",
        "       \n",
        "\n",
        "      # refit ml pipe only with main fetures\n",
        "      # (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "      #                                             variables = ['MultipleLines', 'Partner', 'Contract', \n",
        "      #                                                          'PaymentMethod', 'DeviceProtection', \n",
        "      #                                                          'OnlineSecurity', 'StreamingTV']\n",
        "      #                                             )\n",
        "      # ),\n",
        "       \n",
        "       \n",
        "       \n",
        "\n",
        "      (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables=None, method=\"spearman\",\n",
        "                                                           threshold=0.6,selection_method=\"variance\")\n",
        "      ),\n",
        "       \n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return pipeline_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWTrFyxZWVar"
      },
      "source": [
        "### Hyperparameter Optmization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF9V5_ctHbO7"
      },
      "source": [
        "* Pipeline Optmization: Add Feature Scaling, Feature Selection and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8lGTb0yHbZq"
      },
      "source": [
        "def PipelineOptmization(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"scaler\", StandardScaler()])\n",
        "  pipe.steps.append([\"feat_selection\", SelectFromModel(model)])\n",
        "  pipe.steps.append([\"model\", model])\n",
        "  \n",
        "  return pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDmjjF3tHuCU"
      },
      "source": [
        "* Custom Class for hyperparameter Optmization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpTcVDtQ5RMc"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "class HyperparameterOptmizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model=  PipelineOptmization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            # print(k)\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvwabO0JsmYW"
      },
      "source": [
        "# Features Profile before hitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qufL2HWrF8ig"
      },
      "source": [
        "### Supporting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Zy_MglsmYo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr_pps(df,threshold):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=(20,12))\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                        mask=mask,cmap='rocket_r', annot_kws={\"size\": 8})\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr_pps(df=df_corr_spearman, threshold=CorrThreshold)\n",
        "  \n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr_pps(df=df_corr_pearson, threshold=CorrThreshold)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_corr_pps(df=pps_matrix,threshold=PPS_Threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VlnCBsSdhc-"
      },
      "source": [
        "### Transform the data before hitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1Qr3Xxmdg-D"
      },
      "source": [
        "FeaturesTrainSet = df.copy().drop(['tenure'],axis=1)\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(FeaturesTrainSet)\n",
        "                                        .columns)\n",
        "\n",
        "\n",
        "pipeline_before_model = PipelineDataCleaningAndFeatureEngineering()\n",
        "df_before_hitting_model = pd.DataFrame(data = pipeline_before_model.fit_transform(FeaturesTrainSet),\n",
        "                                       columns = columns_after_data_cleaning_feat_eng\n",
        "                                      #  columns=['PCA0','PCA1','PCA2']\n",
        "                                       )\n",
        "\n",
        "df_before_hitting_model = pd.concat([df_before_hitting_model,df['tenure'].reset_index(drop=True)],axis=1)\n",
        "\n",
        "print(df_before_hitting_model.shape)\n",
        "df_before_hitting_model.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vrJR3urxZ43"
      },
      "source": [
        "# import sklearn.preprocessing\n",
        "# target_transformer = sklearn.preprocessing.PowerTransformer(method='box-cox',standardize=True)\n",
        "\n",
        "\n",
        "# df_before_hitting_model['RainfallTomorrow'] = (target_transformer\n",
        "#                                                .fit_transform(\n",
        "#                                                    df_before_hitting_model['RainfallTomorrow'].values.reshape(-1, 1)))\n",
        "# df_before_hitting_model.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab5lQQBKcAeZ"
      },
      "source": [
        "### Data Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ex7eUUzcAmF"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df_before_hitting_model, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryNo1VnXSK9K"
      },
      "source": [
        "### Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r4AvQPhtS_0"
      },
      "source": [
        "* Calculate Correlations (Pearson and Spearman) and PPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Z4SXf6GbED"
      },
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df_before_hitting_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ-0L4PiSPEK"
      },
      "source": [
        "* Display at Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioE3yuC4Q7QK"
      },
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,\n",
        "                  CorrThreshold=0.6, PPS_Threshold=0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq-C2GQnwhaN"
      },
      "source": [
        "sns.pairplot(data=df_before_hitting_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQBjAlRsHhU4"
      },
      "source": [
        "# Modeling - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpxaylKk-6CQ"
      },
      "source": [
        "* Quick recap in our raw dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfKHc63v-6Zm"
      },
      "source": [
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD6B3CuhiDMT"
      },
      "source": [
        "* Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pFzP2iGiIk1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['tenure'],axis=1),\n",
        "                                    df['tenure'],\n",
        "                                    test_size=config.TEST_SIZE,\n",
        "                                    random_state=config.RANDOM_STATE\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j285uIq1f3h3"
      },
      "source": [
        "### Target Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0IYJz0uf2CT"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pingouin as pg\n",
        "\n",
        "def Target_DistributionAndStats(y_train,y_test):\n",
        "\n",
        "  figure, ax = plt.subplots(nrows=1, ncols=2,figsize=(12,3))\n",
        "  sns.histplot(x=y_train, kde=True,ax=ax[0]).set(title='y train')\n",
        "  sns.histplot(x=y_test, kde=True,ax=ax[1]).set(title='y test')\n",
        "  plt.show();\n",
        "\n",
        "  print(\"\\n* Train set - normality test: \\n\", pg.normality(y_train,method='shapiro',alpha=0.05));\n",
        "  print(\"\\n* Train set - target descriptive stats: \\n\", y_train.describe().round(3).T)\n",
        "  print(f\"\\n* Train set skewness: {y_train.skew().round(3)}, and kurtosis: {y_train.kurt().round(3)} \\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4TsdEhkhlht"
      },
      "source": [
        "Target_DistributionAndStats(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUSDkpgSnNed"
      },
      "source": [
        "#### Target Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqTCBJMua4QS"
      },
      "source": [
        "import sklearn.preprocessing\n",
        "target_transformer = sklearn.preprocessing.PowerTransformer(method='box-cox',standardize=True)\n",
        "\n",
        "y_train = target_transformer.fit_transform(y_train.to_frame())      #.ravel()\n",
        "y_train = pd.Series(y_train.reshape(-1), name='tenure')\n",
        "\n",
        "y_test = target_transformer.transform(y_test.to_frame())          #.ravel()\n",
        "y_test = pd.Series(y_test.reshape(-1), name='tenure')\n",
        "\n",
        "# target_transformer.inverse_transform(y_test.values.reshape(-1,1)) # test for inverse_transform\n",
        "Target_DistributionAndStats(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-15-sWUST6XX"
      },
      "source": [
        "### GridSearch CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTFXq-ieogBj"
      },
      "source": [
        "#### Quick Search using model's default hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3UrUfXNPwwH"
      },
      "source": [
        "* It gives an overall idea of which models may and may not fit your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZKV86gsPw8c"
      },
      "source": [
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"Ridge\": Ridge(random_state=config.RANDOM_STATE),\n",
        "    \"RidgeCV\": RidgeCV(),\n",
        "    \"Lasso\": Lasso(random_state=config.RANDOM_STATE),\n",
        "    \"BayesianRidge\": BayesianRidge(),\n",
        "    \"SGDRegressor\": SGDRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"ElasticNet\": ElasticNet(random_state=config.RANDOM_STATE),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=config.RANDOM_STATE),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    'Ridge': {},\n",
        "    \"RidgeCV\": {},\n",
        "    \"Lasso\": {},\n",
        "    \"BayesianRidge\": {},\n",
        "    \"SGDRegressor\":{},\n",
        "    \"ElasticNet\": {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGABtSoSLP9u"
      },
      "source": [
        "* Do a hyperparameter optmization search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_q-ru92GiBb"
      },
      "source": [
        "quick_search = HyperparameterOptmizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "quick_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)\n",
        "\n",
        "# beep to inform end of training\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7p56nXeoqWo"
      },
      "source": [
        "* Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4YlrmZooiw"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igjPv1kxZ38P"
      },
      "source": [
        "* Check best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBzm_jEZ4FD"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_jvnR4sZ8km"
      },
      "source": [
        "* Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2my-LZFzZ-YD"
      },
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgWXlprwaAW-"
      },
      "source": [
        "* Define the best regressor, based on quick search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OZ24jS0aAfP"
      },
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9uT2XmaKISR"
      },
      "source": [
        "* Most important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m6NUUa0KFQX"
      },
      "source": [
        "# after data cleaning and feat engine, the feature space changes\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Attribute': columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()],\n",
        "          'Importance': best_regressor_pipeline['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Attribute'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Attribute',y='Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzNyQirSKJj6"
      },
      "source": [
        "* Model Evaluation on Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgBgrKJ5KFcX"
      },
      "source": [
        "model_score_train_test_set(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "# PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,best_regressor_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6NA0_8DhV4-"
      },
      "source": [
        "#### Hyperparameters for extensive search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbpH_QRWotKC"
      },
      "source": [
        "* Define models and parameters, based on Quick Search\n",
        "  * As a rule of thumb, select the top 5 models in the Quick Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FuoR6kohaj3"
      },
      "source": [
        "models_search = {\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=config.RANDOM_STATE),\n",
        "    # \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=config.RANDOM_STATE),\n",
        "    # \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=config.RANDOM_STATE),\n",
        "    # \"RandomForestRegressor\": RandomForestRegressor(random_state=config.RANDOM_STATE),\n",
        "    # \"SGDRegressor\": SGDRegressor(random_state=config.RANDOM_STATE),\n",
        "}\n",
        "\n",
        "\n",
        "params_search = {\n",
        "    # https://xgboost.readthedocs.io/en/latest/parameter.html\n",
        "    'XGBRegressor': {\n",
        "        'model__n_estimators':[320], # [300,320,350,370,400], # [100,50,150,300],\n",
        "        'model__max_depth ': [6], # [6,None,15],   # greater more complex\n",
        "\n",
        "        'model__learning_rate': [0.1], # [0.1,0.05,0.01], # [0.3, 0.1, 0.5, 0.7], #greater more complex\n",
        "        'model__min_child_weight': [1], # [1,0.75], #[1,0.01,0.5], # lower more complex\n",
        "\n",
        "        'model__subsample': [1], # [1, 0.5, 0.01],\n",
        "        'model__colsample_bytree':[1], # [1, 0.7, 0.5],\n",
        "\n",
        "        'model__alpha': [0], #[0,0.2,0.5],   # increase more conservative\n",
        "        'model__booster': ['gbtree'], # [\"gbtree\",\"gblinear\"],  # deu gbtree\n",
        "\n",
        "        # 'model__gamma': [0,0.3,1],   # larger, more conservative, just to make test\n",
        "        # 'model__lambda': [0,0.3,1],   # larger, more conservative, just to make test\n",
        "\n",
        "        \n",
        "        },\n",
        "\n",
        "    # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "     \"GradientBoostingRegressor\": {\n",
        "         'model__n_estimators': [100,10,50,250],\n",
        "         'model__learning_rate': [0.1,0.01,0.001], ## increase?\n",
        "         'model__max_depth': [3,None,10],\n",
        "         'model__min_samples_split':  [2,10,45],\n",
        "         'model__min_samples_leaf': [1,20,50],\n",
        "         'model__max_leaf_nodes': [None,5],\n",
        "         },\n",
        "         \n",
        "      #  https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html\n",
        "      \"ExtraTreesRegressor\": {\n",
        "        'model__n_estimators': [100,10,50,250],\n",
        "        'model__max_depth': [None,3,8],\n",
        "        'model__min_samples_leaf': [1,20,50],\n",
        "        'model__max_leaf_nodes': [None,5,10],\n",
        "        'model__min_samples_split': [2,10,45],\n",
        "        'model__bootstrap': [False,True],\n",
        "        'model__oob_score': [False,True],\n",
        "      },\n",
        "\n",
        "      # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
        "      \"RandomForestRegressor\": {\n",
        "        'model__n_estimators': [100,10,50,300],\n",
        "        'model__max_depth': [None,3,10],\n",
        "        'model__min_samples_leaf': [1,20,40],\n",
        "        'model__max_leaf_nodes': [None,5,10],\n",
        "        'model__min_samples_split': [2,50],\n",
        "        'model__bootstrap': [True,False],\n",
        "        'model__oob_score': [False,True],\n",
        "      },\n",
        "\n",
        "      # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
        "      \"SGDRegressor\": {\n",
        "        'model__penalty': [\"l2\", \"l1\", \"elasticnet\"],\n",
        "        'model__loss': [\"squared_loss\",\"huber\",\"epsilon_insensitive\"],\n",
        "        'model__alpha': [1e-4,1e-5,1e-3],\n",
        "        'model__tol': [1e-3,1e-2,1e-4],\n",
        "        'model__learning_rate': [\"invscaling\",\"constant\",\"optimal\",\"adaptive\"], \n",
        "        'model__epsilon': [0.1,0.01]\n",
        "      },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBxJ_CHDiE3s"
      },
      "source": [
        "* Do an extensive hyperparameter optmization search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyiLKoociEO4"
      },
      "source": [
        "extensive_search = HyperparameterOptmizationSearch(models=models_search, params=params_search)\n",
        "extensive_search.fit(X_train, y_train, scoring='r2', n_jobs=-1,cv=5)\n",
        "\n",
        "# beep to inform end of training\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09e2OHRriNP3"
      },
      "source": [
        "* Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ipo-xyf8rC0"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = extensive_search.score_summary(sort_by='max_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNhewN-3Wp9z"
      },
      "source": [
        "* Check the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfo868YvWqGr"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFLS7PUXXC9o"
      },
      "source": [
        "* Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvZaNQC0XDDp"
      },
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3308krlZw_6"
      },
      "source": [
        "* Defining the best regressor pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7kSCrfTXPGo"
      },
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJjjBGL4bLG1"
      },
      "source": [
        "* Most important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5jfRQLbPEY"
      },
      "source": [
        "# after data cleaning and feat engine, the feature space changes\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()].to_list()\n",
        "print(f\"* These are the {len(best_features)} most important features. \"\n",
        "      f\"The model was trained on them: \\n{best_features}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D7GWQygKb5F"
      },
      "source": [
        "* Model Evaluation on Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbmt5UqpKb_W"
      },
      "source": [
        "model_score_train_test_set(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,best_regressor_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ9tjLxEIn3h"
      },
      "source": [
        "# Regressor adding PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPWv-kTBKnjR"
      },
      "source": [
        "* It will change only the PipelineOptmization() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfU562GBIsB1"
      },
      "source": [
        "def PipelineOptmization(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"PCA\",PCA(n_components=3,random_state=config.RANDOM_STATE)])\n",
        "  pipe.steps.append([\"scaler\", StandardScaler()])\n",
        "  pipe.steps.append([\"model\", model])\n",
        "  \n",
        "  return pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDY4EIgrJkKS"
      },
      "source": [
        "* It gives an overall idea of which models may and may not fit your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XmJNoUcJkKX"
      },
      "source": [
        "models_quick_search = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    \"Ridge\": Ridge(random_state=config.RANDOM_STATE),\n",
        "    \"RidgeCV\": RidgeCV(),\n",
        "    \"Lasso\": Lasso(random_state=config.RANDOM_STATE),\n",
        "    \"BayesianRidge\": BayesianRidge(),\n",
        "    \"SGDRegressor\": SGDRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"ElasticNet\": ElasticNet(random_state=config.RANDOM_STATE),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=config.RANDOM_STATE),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=config.RANDOM_STATE),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'LinearRegression': {},\n",
        "    'Ridge': {},\n",
        "    \"RidgeCV\": {},\n",
        "    \"Lasso\": {},\n",
        "    \"BayesianRidge\": {},\n",
        "    \"SGDRegressor\":{},\n",
        "    \"ElasticNet\": {},\n",
        "    \"DecisionTreeRegressor\": {},\n",
        "    \"RandomForestRegressor\": {},\n",
        "    \"ExtraTreesRegressor\": {},\n",
        "    \"AdaBoostRegressor\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\": {},\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq8td65fJkKY"
      },
      "source": [
        "* Do a hyperparameter optmization search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1BdqEB6JkKZ"
      },
      "source": [
        "quick_search = HyperparameterOptmizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "quick_search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)\n",
        "\n",
        "# beep to inform end of training\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ_Xj5oGJkKZ"
      },
      "source": [
        "* Check results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIC2csxKJkKZ"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='max_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3QJ5d7GJkKc"
      },
      "source": [
        "* Check best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-qRFydjJkKc"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36pkvgIDJkKd"
      },
      "source": [
        "* Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LSZGU89JkKe"
      },
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbqEPL1JkKe"
      },
      "source": [
        "* Define the best regressor, based on quick search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z07qQrFwJkKf"
      },
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78tt_ZkiJRdE"
      },
      "source": [
        "model_score_train_test_set(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,best_regressor_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpKz9qjRUOR0"
      },
      "source": [
        "# Change ML Task to Classifer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0yf7s9LVZFH"
      },
      "source": [
        "## Convert target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eG5r24uv7JN"
      },
      "source": [
        "Convert numerical continious target to equal frequency bins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzXQjVf-Uoay"
      },
      "source": [
        "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
        "disc = EqualFrequencyDiscretiser(q=2, variables=['tenure'])\n",
        "\n",
        "df_clf = disc.fit_transform(df)\n",
        "df_clf['tenure'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaElij1Wv_gL"
      },
      "source": [
        "Visualize target distribution and range levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-sJMpuVPuR"
      },
      "source": [
        "print(f\"* The classes represent the following ranges: \\n{disc.binner_dict_} \\n\")\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.countplot(data=df_clf,x='tenure')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSQ8aYrowW2P"
      },
      "source": [
        "Split train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69xEQSzPiSOW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df_clf.drop(['tenure'],axis=1),\n",
        "                                    df_clf['tenure'],\n",
        "                                    test_size=config.TEST_SIZE,\n",
        "                                    random_state=config.RANDOM_STATE\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qniEarknwa3d"
      },
      "source": [
        "Check if target is balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KvzNqhRjFxk"
      },
      "source": [
        "y_train.value_counts(normalize=True).round(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkPaGZfiXexn"
      },
      "source": [
        "## Pipeline for Clf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I53mlfqRUSzn"
      },
      "source": [
        "def PipelineOptmization(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"scaler\", StandardScaler()])\n",
        "  pipe.steps.append([\"feat_selection\", SelectFromModel(model)])\n",
        "  pipe.steps.append([\"model\", model])\n",
        "  return pipe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvkMORvOft14"
      },
      "source": [
        "from sklearn.svm import SVC \n",
        "from sklearn.svm import LinearSVC \n",
        "from sklearn.svm import NuSVC \n",
        "\n",
        "# # Nearest Neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "\n",
        "# # GaussianProcess\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "# # Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.naive_bayes import ComplementNB \n",
        "from sklearn.naive_bayes import BernoulliNB \n",
        "from sklearn.naive_bayes import CategoricalNB \n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "\n",
        "# # Decision Trees\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "# # Ensemble methods - goal is to combine the predictions of several base estimators\n",
        "# # in order to improve generalizability / robustness over a single estimator\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "# # XG boost\n",
        "from xgboost import XGBClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfW5jSmSe7Gl"
      },
      "source": [
        "models_quick_search = {\n",
        "    'RidgeClassifier': RidgeClassifier(config.RANDOM_STATE),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=config.RANDOM_STATE),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=config.RANDOM_STATE),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=config.RANDOM_STATE),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=config.RANDOM_STATE),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=config.RANDOM_STATE),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=config.RANDOM_STATE),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=config.RANDOM_STATE)\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    'RidgeClassifier': {},\n",
        "    \"XGBClassifier\":{},\n",
        "    \"DecisionTreeClassifier\":{},\n",
        "    \"RandomForestClassifier\":{},\n",
        "    \"GradientBoostingClassifier\":{},\n",
        "    \"ExtraTreesClassifier\":{},\n",
        "    \"AdaBoostClassifier\":{},\n",
        "    \"XGBClassifier\":{},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh-nd-JCfX7M"
      },
      "source": [
        "from sklearn.metrics import recall_score, make_scorer\n",
        "quick_search = HyperparameterOptmizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "quick_search.fit(X_train, y_train,\n",
        "                 scoring =  make_scorer(recall_score , pos_label=0),\n",
        "                 n_jobs=-1,cv=5)\n",
        "\n",
        "# beep to inform end of training\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXUbzctLfXd2"
      },
      "source": [
        "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6R2wXm0XbjG"
      },
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXPyDbbxYbv6"
      },
      "source": [
        "grid_search_pipelines[best_model].best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTrUEOcBYby4"
      },
      "source": [
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGc1W7wEM2GP"
      },
      "source": [
        "* Check Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfckT_bFxFaE"
      },
      "source": [
        "# after data cleaning and feat engine, the feature space changes\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[pipeline_clf['feat_selection'].get_support()].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Attribute': columns_after_data_cleaning_feat_eng[pipeline_clf['feat_selection'].get_support()],\n",
        "          'Importance': pipeline_clf['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Attribute'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Attribute',y='Importance')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwI6U28UV4C"
      },
      "source": [
        "## evaluate pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMcvrPmdXbmP"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def ClfPredictionEvaluation(X,y,pipeline,LabelsMap):\n",
        "\n",
        "  prediction = pipeline.predict(X)\n",
        "\n",
        "  Map = list() \n",
        "  for key, value in LabelsMap.items():\n",
        "    Map.append( str(key) + \": \" + value)\n",
        "\n",
        "  print('---  Confusion Matrix  ---')\n",
        "  print(pd.DataFrame(confusion_matrix(prediction,y),\n",
        "        columns=[ [\"Actual \" + sub for sub in Map] ], \n",
        "        index = [ [\"Prediction \" + sub for sub in Map ]]\n",
        "        # index=['Prediction 0', 'Prediction 1']\n",
        "        ))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "  print('---  Classification Report  ---')\n",
        "  print(classification_report(y, prediction),\"\\n\")\n",
        "\n",
        "\n",
        "def ClfPerformanceTrainTestSet(X_train,y_train,X_test,y_test,pipeline,LabelsMap):\n",
        "  print(\"#### Train Set #### \\n\")\n",
        "  ClfPredictionEvaluation(X_train,y_train,pipeline,LabelsMap)\n",
        "\n",
        "  print(\"#### Test Set ####\\n\")\n",
        "  ClfPredictionEvaluation(X_test,y_test,pipeline,LabelsMap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyX8PsH-0z8z"
      },
      "source": [
        "Creates a dictionary that relates the class and numerical interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGLKOq44xpMw"
      },
      "source": [
        "n_classes = len(disc.binner_dict_['tenure']) - 1\n",
        "classes_ranges = disc.binner_dict_['tenure'][1:-1]\n",
        "\n",
        "LabelsMap = {}\n",
        "for n in range(0,n_classes):\n",
        "  if n == 0:\n",
        "    LabelsMap[n] = f\"<{classes_ranges[0]}\"\n",
        "  elif n == n_classes-1:\n",
        "    LabelsMap[n] = f\"+{classes_ranges[-1]}\"\n",
        "  else:\n",
        "    LabelsMap[n] = f\"{classes_ranges[n-1]} to {classes_ranges[n]}\"\n",
        "\n",
        "LabelsMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no7flbMcYbsz"
      },
      "source": [
        "ClfPerformanceTrainTestSet(X_train, y_train ,X_test, y_test,\n",
        "                        pipeline_clf,\n",
        "                        LabelsMap=LabelsMap )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBtppR73G1Yx"
      },
      "source": [
        "## saving the pipeline and relevant files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vBpPvnaG5Mb"
      },
      "source": [
        "import joblib\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6HfkzarHHbW"
      },
      "source": [
        "LabelsMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPEpdAgPHQaL"
      },
      "source": [
        "try:\n",
        "  os.makedirs(name='outputs/ml_pipeline/predict_tenure')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "joblib.dump(value=LabelsMap ,\n",
        "            filename=\"outputs/ml_pipeline/predict_tenure/LabelsMap.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkr4rcrHDnn"
      },
      "source": [
        "pipeline_clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZPif2aHdyO"
      },
      "source": [
        "joblib.dump(value=LabelsMap ,\n",
        "            filename=\"outputs/ml_pipeline/predict_tenure/clf_pipeline.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCDDylcVV-mZ"
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkNEZQLKV-t5"
      },
      "source": [
        "joblib.dump(value=X_train.columns ,\n",
        "            filename=\"outputs/ml_pipeline/predict_tenure/X_train_columns.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg71Ks3n5F6J"
      },
      "source": [
        "best_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V9X1rG_5GC1"
      },
      "source": [
        "joblib.dump(value=best_features,\n",
        "            filename=\"outputs/ml_pipeline/predict_tenure/best_features.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pIvREPUapgi"
      },
      "source": [
        "## Features Profile before hitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYiUBv_7apgk"
      },
      "source": [
        "### Supporting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-qgY4hNapgm"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr_pps(df,threshold):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=(20,12))\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                        mask=mask,cmap='rocket_r', annot_kws={\"size\": 8})\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr_pps(df=df_corr_spearman, threshold=CorrThreshold)\n",
        "  \n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr_pps(df=df_corr_pearson, threshold=CorrThreshold)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_corr_pps(df=pps_matrix,threshold=PPS_Threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSeBM6JAapgo"
      },
      "source": [
        "### Transform the data before hitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTLVGb2iapgp"
      },
      "source": [
        "FeaturesTrainSet = df_clf.copy().drop(['RainfallTomorrow'],axis=1)\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(FeaturesTrainSet)\n",
        "                                        .columns)\n",
        "\n",
        "\n",
        "pipeline_before_model = Pipeline(ClfPipelineOptmization().steps[:-2])\n",
        "df_before_hitting_model = pd.DataFrame(data = pipeline_before_model.fit_transform(FeaturesTrainSet),\n",
        "                                       columns = columns_after_data_cleaning_feat_eng\n",
        "                                      #  columns=['PCA0','PCA1','PCA2']\n",
        "                                       )\n",
        "\n",
        "df_before_hitting_model = pd.concat([df_before_hitting_model,df_clf['RainfallTomorrow']],axis=1)\n",
        "\n",
        "print(df_before_hitting_model.shape)\n",
        "df_before_hitting_model.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhbFDI2Lapgt"
      },
      "source": [
        "### Data Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIXwHfSYapgu"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df_before_hitting_model, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxt-G6ttapgv"
      },
      "source": [
        "### Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U-vroYzapgw"
      },
      "source": [
        "* Calculate Correlations (Pearson and Spearman) and PPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D5Dc-X0apgw"
      },
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df_before_hitting_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPurE--wapgx"
      },
      "source": [
        "* Display at Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OO0vDZlapgy"
      },
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,\n",
        "                  CorrThreshold=0.6, PPS_Threshold=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uAiMbaWapgy"
      },
      "source": [
        "sns.pairplot(data=df_before_hitting_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBk33tMZpsV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwQ5_7rlii-Q"
      },
      "source": [
        "# TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV3gBxwKilA_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK8LJ9AViptX"
      },
      "source": [
        "def CreateTensorFlowModel():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer='adam',loss='mse')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKAp3TMqranM"
      },
      "source": [
        "# pipeline_before_model =  PipelineDataCleaningAndFeatureEngineering()\n",
        "# X_train_tf = pipeline_before_model.fit_transform(X_train)\n",
        "# X_train_tf = pipeline_before_model.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy_HTrh5i1Pz"
      },
      "source": [
        "model = CreateTensorFlowModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDpunWf6sDkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_p_9i4izyP"
      },
      "source": [
        "model.fit(x=X_train_tf,y=y_train.values,\n",
        "          validation_data=(X_train_tf,y_test.values),\n",
        "          epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU_-bkeNi5A8"
      },
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOYpcvuRj8FU"
      },
      "source": [
        "losses.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtmFP_Ulpnd"
      },
      "source": [
        "# Regressor Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da8GYQBCinpM"
      },
      "source": [
        "## Custom Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJPFLoTciOI5"
      },
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error \n",
        "import numpy as np\n",
        "\n",
        "def model_score_train_test_set(X_train, y_train, X_test, y_test,pipeline):\n",
        "\n",
        "\tprint(\"Model Evaluation \\n\")\n",
        "\tprint(\"* Train Set\")\n",
        "\tPredictionEvaluation(X_train,y_train,pipeline)\n",
        "\n",
        "\tprint(\"* Test Set\")\n",
        "\tPredictionEvaluation(X_test,y_test,pipeline)\n",
        "\n",
        "\n",
        "\n",
        "def PredictionEvaluation(X,y,pipeline):\n",
        "  prediction = pipeline.predict(X)\n",
        "\n",
        "  print('R2 Score:', r2_score(y, prediction).round(3))  \n",
        "  print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))  \n",
        "  print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))  \n",
        "  print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  \n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,pipeline):\n",
        "  pred_train = pipeline.predict(X_train)\n",
        "  pred_test = pipeline.predict(X_test)\n",
        "  Plot_Prediction_vs_Actual(y_train,pred_train,y_test, pred_test)\n",
        "\n",
        "\n",
        "\n",
        "def Plot_Prediction_vs_Actual(TrainActual,TrainPred,TestActual,TestPred):\n",
        "\n",
        "  fig = make_subplots(rows=1, cols=2,\n",
        "      subplot_titles=(\"Train Set\", \"Test Set\")\n",
        "      )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TrainActual,\n",
        "          y=TrainPred,\n",
        "          marker=dict(opacity=0.3),\n",
        "          mode='markers',\n",
        "          name='Prediction x Actual'),\n",
        "      row=1, col=1)\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TrainActual,\n",
        "          y=TrainActual,\n",
        "          mode='lines',\n",
        "          name='Accurate Prediction Reference'),\n",
        "      row=1, col=1)\n",
        "\n",
        "\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TestActual,\n",
        "          y=TestPred,\n",
        "          marker=dict(opacity=0.3),\n",
        "          mode='markers',\n",
        "          name='Prediction x Actual'),\n",
        "      row=1, col=2)\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TestActual,\n",
        "          y=TestActual,\n",
        "          mode='lines',\n",
        "          name='Accurate Prediction Reference'),\n",
        "      row=1, col=2)\n",
        "\n",
        "\n",
        "  # Update xaxis and yaxis properties\n",
        "  fig.update_xaxes(title_text=\"Actual\", row=1, col=1)\n",
        "  fig.update_xaxes(title_text=\"Actual\", row=1, col=2)\n",
        "  fig.update_yaxes(title_text=\"Prediction\", row=1, col=1)\n",
        "  fig.update_yaxes(title_text=\" \", row=1, col=2)\n",
        "\n",
        "\n",
        "\n",
        "  fig.update_layout(\n",
        "      title=' ',\n",
        "      plot_bgcolor='rgba(236,236,236,1)',\n",
        "      showlegend=False\n",
        "      )\n",
        "  fig.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--CTB-H7iqzE"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QeE9he9PIwA"
      },
      "source": [
        "model_score_train_test_set(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,best_regressor_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}